{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5a8lAWOfmmy"
   },
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_bepwPRfmnM"
   },
   "source": [
    "## Assignment 2 - Task 1: Optimization\n",
    "\n",
    "In this task, we introduce several improved stochastic gradient descent (SGD) based optimization methods. \n",
    "\n",
    "Plain/naive SGD is a reasonable method to update neural network parameters. However, there exists two main drawbacks. \n",
    "\n",
    "First, to make SGD perform well, one would need to find an appropriate learning rate and a good initial value for the prameters. Otherwise, the network will get stuck if the learning rate is small, or it will diverge if the learning rate is too large. In reality, since we have no prior knowledge about the training data, it is not trivial to find a good learning rate manually. Also, when the network becomes deeper, for each layer one may need to set a different learning rate. \n",
    "\n",
    "The second issue is that SGD follows strictly to the gradients of the batched data when updating the parameters. This can be problematic with real-world problems as has been demonstrated in the lectures. \n",
    "\n",
    "There are also other common limitations including the lack of sufficient training data. This can cause the training to get stuck when using the naive SGD method. These are the limitations of plain SGD, which are motivators for creating and using improved SGD-based methods. \n",
    "\n",
    "To seek for improvements of naive SGD, one can rely on momentum, parameter estimation and adaptive learning rate methods. Here, you are going to experiment with **SGD with momentum**, **SGD with Nesterov momentum**, **Adam**, **SGD with momentum & backtrace** and compare them against one another.\n",
    "\n",
    "Consult the slides and [text book](https://www.deeplearningbook.org) for details. Here is also [a useful link](http://ruder.io/optimizing-gradient-descent/) to learn more about some methods used in this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kwQ5NoOfmnP"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da7zcFQffmnd"
   },
   "source": [
    "## Load Fashion-MNIST\n",
    "\n",
    "Here we use a small dataset with only 2500 samples to simulate the \"lack-of-data\" situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1698,
     "status": "ok",
     "timestamp": 1631138412954,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "PpxLY-MWfmne",
    "outputId": "dc0a48ce-34f5-41bb-be66-23a1fb1389bc"
   },
   "outputs": [],
   "source": [
    "# Load the raw Fashion-MNIST data.\n",
    "train, val = fashion_mnist.load_data()\n",
    "\n",
    "X_train_raw, y_train = train\n",
    "X_val_raw, y_val = val\n",
    "\n",
    "X_train = X_train_raw.reshape((X_train_raw.shape[0], X_train_raw.shape[1]**2))\n",
    "X_val = X_val_raw.reshape((X_val_raw.shape[0], X_val_raw.shape[1]**2))\n",
    "\n",
    "#Consider a subset of 2500 samples of the 60000 total images (indexed 10000 ~ 12500)\n",
    "X_val = X_train[10000:10500,:]\n",
    "y_val = y_train[10000:10500]\n",
    "X_train = X_train[10500:12500,:]\n",
    "y_train = y_train[10500:12500]\n",
    "\n",
    "mean_image = np.mean(X_train, axis=0).astype(np.float32)\n",
    "X_train = X_train.astype(np.float32) - mean_image\n",
    "X_val = X_val.astype(np.float32) - mean_image\n",
    "\n",
    "# We have vectorized the data for you. That is, we flatten the 32×32×3 images into 1×3072 Numpy arrays.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20tnMCjyfmnh"
   },
   "source": [
    "## Part 1: Implement Several Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructors provide code snippets for testing student code implementations.\n",
    "\n",
    "The best anticipated achievable accuracies are specific to each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loz33g8Ufmnk"
   },
   "outputs": [],
   "source": [
    "from utils.neuralnets.mlp import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics\n",
    "\n",
    "Assume that the goal is to optimize an objective function $L$ parametrized by $\\theta \\in R^d$, the update rule of an iterative optimization algorithm in general can be formulated as\n",
    "\n",
    "$$\\theta_{t+1} \\gets \\theta_t + \\alpha_t p_t$$\n",
    "\n",
    "where $\\alpha > 0$ is the step size and $p$ is the direction of the update. \n",
    "\n",
    "Both $\\alpha$ and $p$ can be proposed in several ways which result in different optimizers with different performances. \n",
    "\n",
    "Note that in the equations, we ***DO NOT*** take learning rate decay into consideration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_4iVMT2fmnm"
   },
   "source": [
    "### Original SGD with learning rate decay (for comparison purposes only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the gradient of $L$ w.r.t $\\theta$ at time step $t$ be given by\n",
    "\n",
    "$$g_t = \\nabla_{\\theta} L(\\theta_t)$$\n",
    "\n",
    "and $\\theta_t$ denotes the values of the parameters at time $t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD (Stochastic Gradient Descent) algorithm is formulated as\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta g_t$$\n",
    "\n",
    "where $\\eta$ is the ***learning rate***. \n",
    "\n",
    "The final accuracy you should expect is arround 0.1-0.3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4609,
     "status": "ok",
     "timestamp": 1631138989515,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "crxdrUTvfmnn",
    "outputId": "8c1cb517-e687-407d-bcf3-300b29383430"
   },
   "outputs": [],
   "source": [
    "from utils.optimizers import SGDOptim\n",
    "\n",
    "model = MLP(input_dim=X_train.shape[1], hidden_dims=[100, 100], num_classes=10, weight_scale=1e-3, l2_reg=0.0)\n",
    "optimizer = SGDOptim()\n",
    "hist_sgd = optimizer.train(model, X_train, y_train, X_val, y_val, \n",
    "                           num_epoch=15, batch_size=200, learning_rate=1e-2, learning_decay=0.95, \n",
    "                           verbose=False, record_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a direction\n",
    "\n",
    "As naively in SGD, the step size $\\alpha_t = \\eta$ is fixed to be the learning rate and the update direction $p_t = -g_t$ is simply the opposite of the gradient. Now let's look at some algorithms that try to use a different $p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZauLVUBlfmno"
   },
   "source": [
    "### SGD + Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD + Momuntum algorithm is formulated as\n",
    "\n",
    "$$\\begin{aligned}\n",
    "v_t &= \\gamma v_{t-1} + \\eta g_t \\\\\n",
    "\\theta_{t+1} &= \\theta_t - v_t\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $v$ is often called the ***velocity*** (don't confuse with the \"momentum\" we'll talk about in Adam) and $\\gamma$ is the decay factor. \n",
    "\n",
    "$v_0$ is initialized to be $\\mathbb{0}$. \n",
    "\n",
    "The final accuracy you should expect is arround 0.4-0.6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> Implement SGD + Momentum by editing `SGDmomentumOptim` in **./utils/optimizers.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5250,
     "status": "ok",
     "timestamp": 1631139111767,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "oFTM2qtafmno",
    "outputId": "03fbd2a0-336b-4177-98dc-38cb6c5a3027"
   },
   "outputs": [],
   "source": [
    "# Verification code for your implemention\n",
    "# Please don't change anything.\n",
    "\n",
    "from utils.optimizers import SGDmomentumOptim\n",
    "\n",
    "model = MLP(input_dim=X_train.shape[1], hidden_dims=[100, 100], num_classes=10, l2_reg=0.0, weight_scale=1e-3, momentum=0.8)\n",
    "optimizer = SGDmomentumOptim(model, momentum=0.8)\n",
    "hist_sgd_momentum = optimizer.train(model, X_train, y_train, X_val, y_val, \n",
    "                                    num_epoch=15, batch_size=200, learning_rate=1e-2, \n",
    "                                    learning_decay=0.95, verbose=False, record_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5ZEf-udfmnv"
   },
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam (Adaptive Momentum Estimation) algorithm can be formulated into three steps ($\\beta_1, \\beta_2 \\in [0, 1]$ are all decay factors): \n",
    "\n",
    "- Estimate the first momentum (mean) of the gradients\n",
    "\n",
    "$$\\begin{aligned}\n",
    "m_{t+1} &= \\beta_1 m_t + (1 - \\beta_1) g_t \\\\\n",
    "\\hat{m}_{t+1} &= \\frac{m_{t+1}}{1 - \\beta_1^t}\n",
    "\\end{aligned}$$\n",
    "\n",
    "- Estimate the second momentum (variance) of the gradients\n",
    "\n",
    "$$\\begin{aligned}\n",
    "v_{t+1} &= \\beta_2 v_t + (1 - \\beta_2) g_t^2 \\\\\n",
    "\\hat{v}_{t+1} &= \\frac{v_{t+1}}{1 - \\beta_2^t}\n",
    "\\end{aligned}$$\n",
    "\n",
    "- Update the parameters ($\\epsilon$ is a small value like 1e-8 serves to avoid zero-division)\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_{t+1}}+\\epsilon} \\odot \\hat{m}_{t+1}$$\n",
    "\n",
    "Here, $\\epsilon$ is a small value (e.g. 1e-8) serves to avoid zero-division and $\\odot$ denotes the Hadamard (element-wise) product. \n",
    "\n",
    "The final accuracy you should expect is arround 0.6-0.8. \n",
    "\n",
    "Both $m_0$ and $v_0$ are initialized to be $\\mathbb{0}$. \n",
    "\n",
    "#### This is usually (not always) the optimal choice in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> Implement Adam by editing `AdamOptim` in **./utils/optimizers.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5220,
     "status": "ok",
     "timestamp": 1631139271319,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "aTws4phjfmnw",
    "outputId": "90f0732d-6062-4b8e-ffaf-6978d05958bf"
   },
   "outputs": [],
   "source": [
    "# Verification code for your implemention\n",
    "# Please don't change anything.\n",
    "\n",
    "from utils.optimizers import AdamOptim\n",
    "\n",
    "model = MLP(input_dim=X_train.shape[1], hidden_dims=[100, 100], num_classes=10, l2_reg=0.0, weight_scale=1e-3)\n",
    "optimizer = AdamOptim(model)\n",
    "hist_adam = optimizer.train(model, X_train, y_train, X_val, y_val, \n",
    "                            num_epoch=15, batch_size=200, learning_rate=1e-3, \n",
    "                            learning_decay=0.95, verbose=False, record_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nadam (Nesterov-accelerated Adam) algorithm can be simply derived from Adam. Recall the Adam update rule: \n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_{t+1}}+\\epsilon} \\odot \\hat{m}_{t+1}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\hat{m}_{t+1} = \\frac{\\beta_1 m_t}{1 - \\beta_1^t} + \\frac{(1 - \\beta_1) g_t}{1 - \\beta_1^t}\n",
    "= \\beta_1 \\hat{m}_t + \\frac{(1 - \\beta_1) g_t}{1 - \\beta_1^t}\n",
    "$$ \n",
    "\n",
    "is an estimation of $m_{t+1}$ using the gradients at time $t$. So for Adam we actually have \n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_{t+1}}+\\epsilon} \\odot \n",
    "(\\beta_1 \\hat{m}_t + \\frac{(1 - \\beta_1) g_t}{1 - \\beta_1^t})\n",
    "$$\n",
    "\n",
    "To perform a Nesterov-acceleration, we directly replace the $\\hat{m}_t$ in the above equation with one step of look-ahead: \n",
    "\n",
    "$$\\hat{m}_{t} \\to \\hat{m}_{t+1}$$\n",
    "\n",
    "The final update rule is given by\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_{t+1}}+\\epsilon} \\odot \n",
    "(\\beta_1 \\hat{m}_{t+1} + \\frac{(1 - \\beta_1) g_t}{1 - \\beta_1^t})\n",
    "$$\n",
    "\n",
    "All intermediate parameters including $m$ and $v$ are computed in the same way as in Adam. \n",
    "\n",
    "The final accuracy you should expect is arround 0.7-0.9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> Implement Nadam by editing `NadamOptim` in **./utils/optimizers.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification code for your implemention\n",
    "# Please don't change anything.\n",
    "\n",
    "from utils.optimizers import NadamOptim\n",
    "\n",
    "model = MLP(input_dim=X_train.shape[1], hidden_dims=[100, 100], num_classes=10, l2_reg=0.0, weight_scale=1e-3)\n",
    "optimizer = NadamOptim(model, beta1=0.9, beta2=0.999, eps=1e-8)\n",
    "hist_sgd_nadam = optimizer.train(model, X_train, y_train, X_val, y_val, \n",
    "                                         num_epoch=15, batch_size=200, learning_rate=1e-3, \n",
    "                                         learning_decay=0.95, verbose=False, record_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a step size\n",
    "\n",
    "Recall the general parameter update rule:\n",
    "\n",
    "$$\\theta_{t+1} \\gets \\theta_t + \\alpha_t p_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the basis of SGD, we have already come across three other algorithms that seeks different $p_t$ (with $\\alpha_t = \\eta$):\n",
    "- SGD + Momentum: $p_t = -\\frac{\\gamma}{\\eta} m_{t-1} - g_t$ is the velocity\n",
    "- Adam: $p_t =  -\\frac{1}{\\sqrt{\\hat{v}_{t+1}}+\\epsilon} \\odot \\hat{m}_{t+1}$ is the variance-adjusted estimated momentum\n",
    "- Nadam: $p_t = -\\frac{1}{\\sqrt{\\hat{v}}+\\epsilon} \\odot (\\beta_1 \\hat{m}_{t+1} + \\frac{(1 - \\beta_1) g_t}{1 - \\beta_1^t})$ is the variance-adjusted estimated Nesterov-accelerated momentum\n",
    "\n",
    "Now let's forget $p$ and look at another algorithm that tries to select different $\\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD + Momentum + Backtrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backtracing line search is a famous method that starts with a fairly large initial step size, and then repeatedly ***tries*** to search for a slightly smaller step until an appropriate one is met. For some loss function $L$, given an initial step size $\\alpha_t > 0$ and an update direction $p_t$, the algorithms finds the appropriate step size following: \n",
    "\n",
    "> $\\alpha \\gets \\alpha_t$ <br>\n",
    "> while $L(\\theta_t + \\alpha p_t) > L(\\theta_t) + c \\alpha g_t^T p_t$: <br>\n",
    "> &emsp; $\\alpha \\gets \\rho \\alpha$ <br>\n",
    "> return $\\alpha_t = \\alpha$\n",
    "\n",
    "For the loop criterion, observe that the LHS term \n",
    "\n",
    "$$L(\\theta_t + \\alpha p_t)$$ \n",
    "\n",
    "This is the value of the loss function **after** the potential update, which is forced to be smaller than a linear **upper bound** provided by the RHS term \n",
    "\n",
    "$$L(\\theta_t) + c \\alpha g_t^T p_t$$\n",
    "\n",
    "This is call the **Armijo (sufficient decrease)** condition, stating that either after the current search the loss function decreases below the upperbound after the update, or else we **abandon the current search results**, find a new (smaller) step size and try again for another update. \n",
    "\n",
    "The step size in trial is decreased by a factor $\\rho \\in [0, 1]$ after every search step, and $c \\in [0, 1]$ controls the **slope** (\"hardness\") of the linear upper bound. \n",
    "\n",
    "Since in here we're searching for $\\theta_{t+1}$ in a linear subspace of $\\theta$ parametrized by $\\alpha$, these types of algorithms are called a [*Line Search*](https://optimization.cbe.cornell.edu/index.php?title=Line_search_methods). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD + Momentum + Backtrace first proposes to find the update direction $p_t$ with momentum as discussed in previous sections, then tries to select an ideal $\\alpha_t$ using backtracing line search. \n",
    "\n",
    "The accuracy you should expect is arround 0.7-0.9. This is NOT a commonly used method in DL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> Implement SGD + Momentum + Backtrace by editing `SGDmomtraceOptim` in **./utils/optimizers.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification code for your implemention\n",
    "# Please don't change anything.\n",
    "\n",
    "from utils.optimizers import SGDmomtraceOptim\n",
    "\n",
    "model = MLP(input_dim=X_train.shape[1], hidden_dims=[100, 100], num_classes=10, l2_reg=0.0, weight_scale=1e-3)\n",
    "optimizer = SGDmomtraceOptim(model, momentum=0.8, alpha1=1, alpha2=0.9, max_searches=20, eps=1e-8)\n",
    "hist_momtrace = optimizer.train(model, X_train, y_train, X_val, y_val, \n",
    "                                num_epoch=15, batch_size=200, learning_rate=1e-2, \n",
    "                                learning_decay=1, verbose=False, record_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dga2dgGxfmny"
   },
   "source": [
    "## Part 2: Comparison\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Run the following cells, which plot the loss, training accuracy, and validation accuracy curves of different optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mzui75QUfmny"
   },
   "outputs": [],
   "source": [
    "loss_hist_sgd, train_acc_hist_sgd, val_acc_hist_sgd = hist_sgd\n",
    "loss_hist_momentum, train_acc_hist_momentum, val_acc_hist_momentum = hist_sgd_momentum\n",
    "loss_hist_adam, train_acc_hist_adam, val_acc_hist_adam = hist_adam\n",
    "loss_hist_nesterov, train_acc_hist_nesterov, val_acc_hist_nesterov = hist_sgd_nadam\n",
    "loss_hist_momtrace, train_acc_hist_momtrace, val_acc_hist_momtrace = hist_momtrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1631139318716,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "oX9CyZjLfmnz",
    "outputId": "ce4a99cd-8663-4a2c-cdca-6ab7b95125c9"
   },
   "outputs": [],
   "source": [
    "# Plot the training error curves for implemented optimizers\n",
    "plt.plot(loss_hist_sgd, label=\"sgd\")\n",
    "plt.plot(loss_hist_momentum, label=\"momentum\")\n",
    "plt.plot(loss_hist_adam, label=\"adam\")\n",
    "plt.plot(loss_hist_nesterov, label=\"nadam\")\n",
    "plt.plot(loss_hist_momtrace, label=\"momtrace\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1631139328348,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "JVigWVU1fmn0",
    "outputId": "c836fcfb-5350-4fbc-ccee-32270aa834e8"
   },
   "outputs": [],
   "source": [
    "# Plot the training accuracy curves for implemented optimizers\n",
    "plt.plot(train_acc_hist_sgd, label=\"sgd\")\n",
    "plt.plot(train_acc_hist_momentum, label=\"momentum\")\n",
    "plt.plot(train_acc_hist_adam, label=\"adam\")\n",
    "plt.plot(train_acc_hist_nesterov, label=\"nadam\")\n",
    "plt.plot(train_acc_hist_momtrace, label=\"momtrace\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1631139339586,
     "user": {
      "displayName": "Sung Jun Won",
      "photoUrl": "",
      "userId": "15792990474350106348"
     },
     "user_tz": 240
    },
    "id": "7AIf6zjpfmn1",
    "outputId": "25c10de5-13a4-40f9-e721-68f2d9ceb852"
   },
   "outputs": [],
   "source": [
    "# Plot the validation accuracy curves for implemented optimizers\n",
    "plt.plot(val_acc_hist_sgd, label=\"sgd\")\n",
    "plt.plot(val_acc_hist_momentum, label=\"momentum\")\n",
    "plt.plot(val_acc_hist_adam, label=\"adam\")\n",
    "plt.plot(val_acc_hist_nesterov, label=\"nadam\")\n",
    "plt.plot(val_acc_hist_momtrace, label=\"momtrace\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4aY4q4wfmn2"
   },
   "source": [
    "<span style=\"color:red\">__TODO:__</span> Describe your results, and discuss your understandings of these optimizers, such as their advantages or disadvantages and when to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL5H31uzfmn3"
   },
   "source": [
    "Answer: **[fill in herer]**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task1-optimization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "36142657f443a869bd2c1b509e6f1df9b014ad48aa206cdd00d27f8f22cb37ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
